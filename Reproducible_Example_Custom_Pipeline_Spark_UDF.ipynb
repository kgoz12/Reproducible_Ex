{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "321674b7-35ef-498d-9148-3f860ed8da2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install torch==2.0.1\n",
    "%pip install transformers==4.29.2\n",
    "%pip install scikit-learn==0.24.2\n",
    "%pip install pyspark==3.4.0\n",
    "%pip install pandas==1.3.4\n",
    "%pip install accelerate==0.20.3\n",
    "%pip install seqeval==1.2.2\n",
    "%pip install datasets==2.12.0\n",
    "%pip install tqdm==4.65.0\n",
    "%pip install evaluate==0.4.0\n",
    "%pip install mlflow==2.9.2\n",
    "%pip install mlflow[pipelines]\n",
    "%pip install torchvision==0.15.2\n",
    "%pip install pytorch-lightning==2.0.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "752ecc34-6d57-4546-881f-afeb30cc4fd2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import LukeTokenizer, LukeModel, LukeForEntityPairClassification, AdamW\n",
    "from transformers import Pipeline, pipeline\n",
    "from transformers.pipelines import PIPELINE_REGISTRY\n",
    "import pyspark.sql.types as T\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85fa34aa-d3dd-41eb-9ad2-8be9c12a433a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# defines the model\n",
    "\n",
    "class LUKE(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = LukeForEntityPairClassification.from_pretrained(\"studio-ousia/luke-large-finetuned-tacred\")\n",
    "        # we can point this to our loaded model to pick up fine tuning, right?\n",
    "\n",
    "    def forward(self, input_ids, entity_ids, entity_position_ids, attention_mask, entity_attention_mask):     \n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, entity_ids=entity_ids, \n",
    "                             entity_attention_mask=entity_attention_mask, entity_position_ids=entity_position_ids)\n",
    "        return outputs\n",
    "    \n",
    "    def common_step(self, batch, batch_idx):\n",
    "        labels = batch['label']\n",
    "        del batch['label']\n",
    "        outputs = self(**batch)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss() # multi-class classification\n",
    "        loss = criterion(logits, labels)\n",
    "        predictions = logits.argmax(-1)\n",
    "        correct = (predictions == labels).sum().item()\n",
    "        accuracy = correct/batch['input_ids'].shape[0]\n",
    "\n",
    "        return loss, accuracy\n",
    "      \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, accuracy = self.common_step(batch, batch_idx)     \n",
    "        self.log(\"training_loss\", loss)\n",
    "        self.log(\"training_accuracy\", accuracy)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, accuracy = self.common_step(batch, batch_idx)     \n",
    "        self.log(\"validation_loss\", loss, on_epoch=True)\n",
    "        self.log(\"validation_accuracy\", accuracy, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    # currently we don't have enough datato create a test set, just train and validation\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, accuracy = self.common_step(batch, batch_idx)     \n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=5e-5)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return valid_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff90388c-90ef-451d-869d-5b0ab231f3c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity-pair-classification is already registered. Overwriting pipeline for task entity-pair-classification...\n['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'entity-pair-classification', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection']\n('entity-pair-classification', {'impl': <class '__main__.EntityPairClassificationPipeline'>, 'pt': (<class 'transformers.models.luke.modeling_luke.LukeForEntityPairClassification'>,), 'tf': (), 'type': 'text'}, None)\n"
     ]
    }
   ],
   "source": [
    "# defines a pipeline compatible w/ model and serves the outputs I want\n",
    "\n",
    "def softmax(outputs):\n",
    "    maxes = np.max(outputs, axis=-1, keepdims=True)\n",
    "    shifted_exp = np.exp(outputs - maxes)\n",
    "    return shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)\n",
    "\n",
    "class EntityPairClassificationPipeline(Pipeline):\n",
    "\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        preprocess_params = {}\n",
    "        if \"entity_spans\" in kwargs:\n",
    "            preprocess_params[\"entity_spans\"] = kwargs[\"entity_spans\"]\n",
    "        return preprocess_params, {}, {}\n",
    "\n",
    "    def __call__(self, text, **kwargs): # entity_spans):\n",
    "        # result = super().__call__(text, entity_spans)\n",
    "        result = super().__call__(text, **kwargs)\n",
    "        return result\n",
    "\n",
    "    # the preproccess function IS NOT successfully getting the entity_spans\n",
    "    def preprocess(self, text, entity_spans=None):\n",
    "        model_inputs = self.tokenizer(text=text, \n",
    "                                      entity_spans=entity_spans, \n",
    "                                      return_tensors=\"pt\"\n",
    "                                      )\n",
    "        return model_inputs\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        return self.model(**model_inputs)\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        logits = model_outputs.logits[0].numpy()\n",
    "        probabilities = softmax(logits)\n",
    "        best_class = np.argmax(probabilities)\n",
    "        label = self.model.config.id2label[best_class]\n",
    "        score = probabilities[best_class].item()\n",
    "        return {\"predicted label\": label, \"confidence score\": score}\n",
    "\n",
    "PIPELINE_REGISTRY.register_pipeline(\n",
    "    \"entity-pair-classification\",\n",
    "    pipeline_class=EntityPairClassificationPipeline,\n",
    "    pt_model=LukeForEntityPairClassification,\n",
    "    type=\"text\"  \n",
    ")\n",
    "\n",
    "print(PIPELINE_REGISTRY.get_supported_tasks())\n",
    "print(PIPELINE_REGISTRY.check_task('entity-pair-classification'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22f6626b-21ba-4973-af54-ca7c4f63b06d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at studio-ousia/luke-large-finetuned-tacred were not used when initializing LukeForEntityPairClassification: ['luke.embeddings.position_ids']\n- This IS expected if you are initializing LukeForEntityPairClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing LukeForEntityPairClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n[(0, 7), (17, 28)]\nOut[6]: {'predicted label': 'per:cities_of_residence',\n 'confidence score': 0.9899731874465942}"
     ]
    }
   ],
   "source": [
    "# demonstrate that the pipeline works locally\n",
    "\n",
    "model = LukeForEntityPairClassification.from_pretrained(\n",
    "    \"studio-ousia/luke-large-finetuned-tacred\",\n",
    "    )\n",
    "\n",
    "tokenizer = LukeTokenizer.from_pretrained(\n",
    "    \"studio-ousia/luke-large-finetuned-tacred\",\n",
    "    max_mention_length = 64,\n",
    "    )\n",
    "\n",
    "# pass the model and previously used classifier to the custom transformers pipeline I created\n",
    "classifier = pipeline(\"entity-pair-classification\",\n",
    "                      model=model,\n",
    "                      tokenizer=tokenizer,\n",
    "                      framework='pt',\n",
    "                      config=model.config,\n",
    "                      ) \n",
    "\n",
    "# send a toy example to the classifier to make sure it works correctly\n",
    "entity_spans_list = ((0, 7), (17, 28))\n",
    "entity_spans_tuple = [tuple(x) for x in entity_spans_list]\n",
    "print(entity_spans_tuple)\n",
    "text1 = \"Beyoncé lives in Los Angeles.\"\n",
    "\n",
    "# call the classifier pipeline function defined above\n",
    "classifier(text=text1, entity_spans=entity_spans_tuple) \n",
    "\n",
    "# should output...\n",
    "# {'predicted label': 'per:cities_of_residence', 'confidence score': 0.9899731874465942}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13027bd3-2500-49be-a230-2b65197f037c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/01/17 20:01:41 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.9.2/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n2024/01/17 20:01:45 WARNING mlflow.transformers: The model card could not be retrieved from the hub due to 404 Client Error. (Request ID: Root=1-65a83228-122d159b63655c1c74b29725;9589dbad-3207-4e2b-8d8d-c5c48aebc0b4)\n\nEntry Not Found for url: https://huggingface.co/studio-ousia/luke-large-finetuned-tacred/resolve/main/README.md.\n2024/01/17 20:01:45 WARNING mlflow.transformers: An unsupported Pipeline type was supplied for signature inference. Either provide an `input_example` or generate a signature manually via `infer_signature` if you would like to have a signature recorded in the MLmodel file.\n2024/01/17 20:02:11 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/repl_tmp_data/ReplId-3536d-aace2-81a75-e/tmppg4q_qdz/model, flavor: transformers), fall back to return ['transformers==4.29.2', 'torch==2.0.1', 'torchvision==0.15.2', 'accelerate==0.20.3']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e28c26dd4084978851f6df3198b3879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/01/17 20:02:12 INFO mlflow.store.artifact.cloud_artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9935f2b1723748038e2a9b2dc7984c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /tmp/repl_tmp_data/ReplId-3536d-aace2-81a75-e/tmppg4q_qdz/model/model/pytorch_model-00002-of-00006.b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log model\n",
    "mlflow.end_run()\n",
    "mlflow.start_run()\n",
    "mlflow.transformers.log_model(\n",
    "    classifier,\n",
    "    artifact_path= \"re_custom_pipeline\",\n",
    "    task=\"entity-pair-classification\",\n",
    "    code_paths=[\"/Workspace/Users/FAKE/FAKE/FAKE/\"]\n",
    "    # code_paths contains .py with class EntityPairClassificationPipeline(Pipeline); class LUKE(pl.LightningModule); PIPELINE_REGISTRY.register_pipeline() \n",
    ")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9f5535f-c50c-4cee-9eeb-cbfe6f6af986",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a6cea2f4284fca98c9f67de7a03de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/01/17 20:12:50 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n2024/01/17 20:13:01 INFO mlflow.transformers: 'runs:/27c7190cf78d493ca4c3d779c73d6581/re_custom_pipeline' resolved as 'dbfs:/databricks/mlflow-tracking/1829326925589999/27c7190cf78d493ca4c3d779c73d6581/artifacts/re_custom_pipeline'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836faaec8dba4034bc8ebce8c15c5e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65d81f415d241c489c62a8b5b64e766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity-pair-classification\nLukeForEntityPairClassification(\n  (luke): LukeModel(\n    (embeddings): LukeEmbeddings(\n      (word_embeddings): Embedding(50267, 1024, padding_idx=1)\n      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (entity_embeddings): LukeEntityEmbeddings(\n      (entity_embeddings): Embedding(500000, 256, padding_idx=0)\n      (entity_embedding_dense): Linear(in_features=256, out_features=1024, bias=False)\n      (position_embeddings): Embedding(514, 1024)\n      (token_type_embeddings): Embedding(1, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): LukeEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x LukeLayer(\n          (attention): LukeAttention(\n            (self): LukeSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (w2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n              (e2w_query): Linear(in_features=1024, out_features=1024, bias=True)\n              (e2e_query): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LukeSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LukeIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LukeOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): LukePooler(\n      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=2048, out_features=42, bias=False)\n)\nLukeTokenizer(name_or_path='/tmp/repl_tmp_data/ReplId-3536d-aace2-81a75-e/tmp0o3kirtp/re_custom_pipeline/components/tokenizer', vocab_size=50265, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True), 'additional_special_tokens': [AddedToken(\"<ent>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"<ent2>\", rstrip=False, lstrip=False, single_word=False, normalized=True)]}, clean_up_tokenization_spaces=True)\nOut[12]: {'predicted label': 'per:cities_of_residence',\n 'confidence score': 0.9899731874465942}"
     ]
    }
   ],
   "source": [
    "# load model \n",
    "loaded_classifier = mlflow.transformers.load_model(\n",
    "    'runs:/27c7190cf78d493ca4c3d779c73d6581/re_custom_pipeline',  # update with runid\n",
    "    return_type=\"pipeline\" \n",
    "    )\n",
    "\n",
    "print(loaded_classifier.task)\n",
    "print(loaded_classifier.model)\n",
    "print(loaded_classifier.tokenizer)\n",
    "\n",
    "# use model locally\n",
    "tup1 = tuple((0, 7))\n",
    "tup2 = tuple((17, 28))\n",
    "my_tuple = [tup1, tup2]\n",
    "text = \"Beyoncé lives in Los Angeles.\"\n",
    "\n",
    "loaded_classifier.__call__(\n",
    "    text=text,\n",
    "    entity_spans=(my_tuple))\n",
    "    \n",
    "# outputs: {'predicted label': 'per:cities_of_residence', 'confidence score': 0.9899731874465942}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "326d01c9-ac20-4c22-b360-b9a5db2a596f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- text: string (nullable = true)\n |-- entity_spans: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- tuple_1: integer (nullable = true)\n |    |    |-- tuple_2: integer (nullable = true)\n\n+--------------------+------------------+\n|                text|      entity_spans|\n+--------------------+------------------+\n|Beyoncé lives in ...|[{0, 7}, {17, 28}]|\n+--------------------+------------------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>text</th><th>entity_spans</th></tr></thead><tbody><tr><td>Beyoncé lives in Los Angeles.</td><td>List(List(0, 7), List(17, 28))</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Beyoncé lives in Los Angeles.",
         [
          [
           0,
           7
          ],
          [
           17,
           28
          ]
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "entity_spans",
         "type": "{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"tuple_1\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"tuple_2\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create spark dataframe for example\n",
    "\n",
    "schema = (\n",
    "    T.StructType([\n",
    "        T.StructField(\"text\", T.StringType(), True),\n",
    "        T.StructField(\"entity_spans\", T.ArrayType(\n",
    "            T.StructType([\n",
    "                T.StructField(\"tuple_1\", T.IntegerType(), True), \n",
    "                T.StructField(\"tuple_2\", T.IntegerType(), True)])))]))\n",
    "\n",
    "spark_df = spark.createDataFrame([(text, (my_tuple))], schema=schema)\n",
    "\n",
    "spark_df.printSchema()\n",
    "spark_df.show()\n",
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbfa911a-1cac-48a9-9fad-743aac009c10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55f17bd90f144e28db5cef5a7b05ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/01/17 20:16:41 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n2024/01/17 20:16:51 WARNING mlflow.pyfunc: Calling `spark_udf()` with `env_manager=\"local\"` does not recreate the same environment that was used during training, which may lead to errors or inaccurate predictions. We recommend specifying `env_manager=\"conda\"`, which automatically recreates the environment that was used to train the model and performs inference in the recreated environment.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626927b0329d47008a514915661a2707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/01/17 20:16:51 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 27.0 failed 4 times, most recent failure: Lost task 0.3 in stage 27.0 (TID 89) (10.21.102.0 executor 3): org.apache.spark.api.python.PythonException: 'KeyError: \"Unknown task entity-pair-classification, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"'. Full traceback below:\n",
       "Traceback (most recent call last):\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/pyfunc/__init__.py\", line 1647, in udf\n",
       "    os.kill(scoring_server_proc.pid, signal.SIGTERM)\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/pyfunc/__init__.py\", line 689, in load_model\n",
       "    raise e\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/transformers/__init__.py\", line 1626, in _load_pyfunc\n",
       "    _load_model(str(local_path), flavor_configuration, \"pipeline\"),\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/transformers/__init__.py\", line 1009, in _load_model\n",
       "    return transformers.pipeline(**conf)\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/transformers/pipelines/__init__.py\", line 744, in pipeline\n",
       "    normalized_task, targeted_task, task_options = check_task(task)\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/transformers/pipelines/__init__.py\", line 487, in check_task\n",
       "    return PIPELINE_REGISTRY.check_task(task)\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/transformers/pipelines/base.py\", line 1194, in check_task\n",
       "    raise KeyError(\n",
       "KeyError: \"Unknown task entity-pair-classification, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"\n",
       "\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:694)\n",
       "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:110)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:647)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
       "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
       "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:761)\n",
       "\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:80)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:186)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:174)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$4(Task.scala:137)\n",
       "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:41)\n",
       "\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:99)\n",
       "\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:104)\n",
       "\tat scala.util.Using$.resource(Using.scala:269)\n",
       "\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:103)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:137)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:96)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:902)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1697)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:905)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:760)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:3381)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:3313)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:3304)\n",
       "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
       "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
       "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:3304)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1428)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1428)\n",
       "\tat scala.Option.foreach(Option.scala:407)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1428)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3593)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3531)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3519)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:51)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$runJob$1(DAGScheduler.scala:1177)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1165)\n",
       "\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2746)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$runSparkJobs$1(Collector.scala:312)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.runSparkJobs(Collector.scala:271)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.collect(Collector.scala:322)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:105)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:112)\n",
       "\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:115)\n",
       "\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:104)\n",
       "\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:88)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.$anonfun$computeResult$1(ResultCacheManager.scala:527)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.collectResult$1(ResultCacheManager.scala:519)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.computeResult(ResultCacheManager.scala:539)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.$anonfun$getOrComputeResultInternal$1(ResultCacheManager.scala:396)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.getOrComputeResultInternal(ResultCacheManager.scala:390)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.getOrComputeResult(ResultCacheManager.scala:292)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollectResult$1(SparkPlan.scala:433)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.executeCollectResult(SparkPlan.scala:430)\n",
       "\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3431)\n",
       "\tat org.apache.spark.sql.Dataset.$anonfun$collectResult$1(Dataset.scala:3422)\n",
       "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$3(Dataset.scala:4297)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:773)\n",
       "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4295)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:249)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:399)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:194)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:985)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:148)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:349)\n",
       "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4295)\n",
       "\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3421)\n",
       "\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation0(OutputAggregator.scala:267)\n",
       "\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation(OutputAggregator.scala:101)\n",
       "\tat com.databricks.backend.daemon.driver.PythonDriverLocalBase.generateTableResult(PythonDriverLocalBase.scala:723)\n",
       "\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.computeListResultsItem(JupyterDriverLocal.scala:1424)\n",
       "\tat com.databricks.backend.daemon.driver.JupyterDriverLocal$JupyterEntryPoint.addCustomDisplayData(JupyterDriverLocal.scala:505)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "Caused by: org.apache.spark.api.python.PythonException: 'KeyError: \"Unknown task entity-pair-classification, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"'. Full traceback below:\n",
       "Traceback (most recent call last):\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/pyfunc/__init__.py\", line 1647, in udf\n",
       "    os.kill(scoring_server_proc.pid, signal.SIGTERM)\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/pyfunc/__init__.py\", line 689, in load_model\n",
       "    raise e\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/transformers/__init__.py\", line 1626, in _load_pyfunc\n",
       "    _load_model(str(local_path), flavor_configuration, \"pipeline\"),\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/transformers/__init__.py\", line 1009, in _load_model\n",
       "    return transformers.pipeline(**conf)\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/transformers/pipelines/__init__.py\", line 744, in pipeline\n",
       "    normalized_task, targeted_task, task_options = check_task(task)\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/transformers/pipelines/__init__.py\", line 487, in check_task\n",
       "    return PIPELINE_REGISTRY.check_task(task)\n",
       "  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/transformers/pipelines/base.py\", line 1194, in check_task\n",
       "    raise KeyError(\n",
       "KeyError: \"Unknown task entity-pair-classification, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"\n",
       "\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:694)\n",
       "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:110)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:647)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
       "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
       "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:761)\n",
       "\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:80)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:186)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:174)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$4(Task.scala:137)\n",
       "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:41)\n",
       "\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:99)\n",
       "\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:104)\n",
       "\tat scala.util.Using$.resource(Using.scala:269)\n",
       "\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:103)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:137)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:96)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:902)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1697)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:905)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:760)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\t... 1 more"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 27.0 failed 4 times, most recent failure: Lost task 0.3 in stage 27.0 (TID 89) (10.21.102.0 executor 3): org.apache.spark.api.python.PythonException: 'KeyError: \"Unknown task entity-pair-classification, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"'. Full traceback below:\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/pyfunc/__init__.py\", line 1647, in udf\n    os.kill(scoring_server_proc.pid, signal.SIGTERM)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/pyfunc/__init__.py\", line 689, in load_model\n    raise e\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/transformers/__init__.py\", line 1626, in _load_pyfunc\n    _load_model(str(local_path), flavor_configuration, \"pipeline\"),\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/transformers/__init__.py\", line 1009, in _load_model\n    return transformers.pipeline(**conf)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/transformers/pipelines/__init__.py\", line 744, in pipeline\n    normalized_task, targeted_task, task_options = check_task(task)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/transformers/pipelines/__init__.py\", line 487, in check_task\n    return PIPELINE_REGISTRY.check_task(task)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/transformers/pipelines/base.py\", line 1194, in check_task\n    raise KeyError(\nKeyError: \"Unknown task entity-pair-classification, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:694)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:110)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:647)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:761)\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:80)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:186)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:174)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$4(Task.scala:137)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:41)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:99)\n\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:104)\n\tat scala.util.Using$.resource(Using.scala:269)\n\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:103)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:137)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:902)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1697)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:905)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:760)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:3381)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:3313)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:3304)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:3304)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1428)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1428)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1428)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3593)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3531)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3519)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:51)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$runJob$1(DAGScheduler.scala:1177)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1165)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2746)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$runSparkJobs$1(Collector.scala:312)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.execution.collect.Collector.runSparkJobs(Collector.scala:271)\n\tat org.apache.spark.sql.execution.collect.Collector.collect(Collector.scala:322)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:105)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:112)\n\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:115)\n\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:104)\n\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:88)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.$anonfun$computeResult$1(ResultCacheManager.scala:527)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.collectResult$1(ResultCacheManager.scala:519)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.computeResult(ResultCacheManager.scala:539)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.$anonfun$getOrComputeResultInternal$1(ResultCacheManager.scala:396)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.getOrComputeResultInternal(ResultCacheManager.scala:390)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.getOrComputeResult(ResultCacheManager.scala:292)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollectResult$1(SparkPlan.scala:433)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollectResult(SparkPlan.scala:430)\n\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3431)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectResult$1(Dataset.scala:3422)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$3(Dataset.scala:4297)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:773)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4295)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:249)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:399)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:194)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:985)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:148)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:349)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4295)\n\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3421)\n\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation0(OutputAggregator.scala:267)\n\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation(OutputAggregator.scala:101)\n\tat com.databricks.backend.daemon.driver.PythonDriverLocalBase.generateTableResult(PythonDriverLocalBase.scala:723)\n\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.computeListResultsItem(JupyterDriverLocal.scala:1424)\n\tat com.databricks.backend.daemon.driver.JupyterDriverLocal$JupyterEntryPoint.addCustomDisplayData(JupyterDriverLocal.scala:505)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.api.python.PythonException: 'KeyError: \"Unknown task entity-pair-classification, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"'. Full traceback below:\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/pyfunc/__init__.py\", line 1647, in udf\n    os.kill(scoring_server_proc.pid, signal.SIGTERM)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/pyfunc/__init__.py\", line 689, in load_model\n    raise e\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/transformers/__init__.py\", line 1626, in _load_pyfunc\n    _load_model(str(local_path), flavor_configuration, \"pipeline\"),\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/mlflow/transformers/__init__.py\", line 1009, in _load_model\n    return transformers.pipeline(**conf)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/transformers/pipelines/__init__.py\", line 744, in pipeline\n    normalized_task, targeted_task, task_options = check_task(task)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/transformers/pipelines/__init__.py\", line 487, in check_task\n    return PIPELINE_REGISTRY.check_task(task)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-4fb885a9-934f-4c6a-a113-d42622273905/lib/python3.9/site-packages/transformers/pipelines/base.py\", line 1194, in check_task\n    raise KeyError(\nKeyError: \"Unknown task entity-pair-classification, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:694)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:110)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:647)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:761)\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:80)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:186)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:174)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$4(Task.scala:137)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:41)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:99)\n\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:104)\n\tat scala.util.Using$.resource(Using.scala:269)\n\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:103)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:137)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:902)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1697)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:905)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:760)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
       "errorSummary": "PythonException: 'KeyError: \"Unknown task entity-pair-classification, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"'. Full traceback below:",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "from pyspark.sql.functions import struct, col\n",
    "logged_model = 'runs:/27c7190cf78d493ca4c3d779c73d6581/re_custom_pipeline'\n",
    "\n",
    "# Load model as a Spark UDF. Override result_type if the model does not return double values.\n",
    "loaded_model = mlflow.pyfunc.spark_udf(\n",
    "    spark, \n",
    "    model_uri=logged_model, \n",
    "    result_type='string',\n",
    "    )\n",
    "\n",
    "# Predict on a Spark DataFrame.\n",
    "display(spark_df.withColumn('predictions', loaded_model(struct(*map(col, spark_df.columns)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4111a248-fb25-4812-affe-2018d911aeaa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Does the call from _validate_transformers_task_type() to get_supported_tasks() (https://github.com/mlflow/mlflow/blob/98aefdf1af299c4ddef898377860e06eda7969f3/mlflow/transformers/__init__.py#L1276) simply call for the list in  https://github.com/huggingface/transformers/blob/f4f57f9dfa68948a383c352a900d588f63f6290a/src/transformers/pipelines/__init__.py#L434?  And is the code in the directory specified by code_paths run once the environment is set up? Could get_supported_tasks() call PIPELINE_REGISTRY.get_supported_tasks() once prepended code is run? "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2151444576101439,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Reproducible_Example_Custom_Pipeline_Spark_UDF",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
